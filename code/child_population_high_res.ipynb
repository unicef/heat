{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19400,"status":"ok","timestamp":1719773780360,"user":{"displayName":"Do-Hyung Kim","userId":"04028744741058070758"},"user_tz":240},"id":"bWNtiFv5ejh9","outputId":"ff8c4771-2e43-4380-aff0-a32b58781600"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","\n","# This will prompt for authorization.\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7769,"status":"ok","timestamp":1719773931604,"user":{"displayName":"Do-Hyung Kim","userId":"04028744741058070758"},"user_tz":240},"id":"WeoPw36P_8TT","outputId":"006f2344-ef8b-4385-aee4-7740439d1006"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.5/21.5 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["! pip install rasterio -q"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8514,"status":"ok","timestamp":1719775036566,"user":{"displayName":"Do-Hyung Kim","userId":"04028744741058070758"},"user_tz":240},"id":"tgekW7vdQL3e","outputId":"8cc020fe-978f-4a5c-e393-9b76b936a477"},"outputs":[{"name":"stdout","output_type":"stream","text":["Reading package lists...\n","Building dependency tree...\n","Reading state information...\n","The following additional packages will be installed:\n","  python3-gdal python3-numpy\n","Suggested packages:\n","  libgdal-grass python-numpy-doc python3-pytest\n","The following NEW packages will be installed:\n","  gdal-bin python3-gdal python3-numpy\n","0 upgraded, 3 newly installed, 0 to remove and 45 not upgraded.\n","Need to get 5,055 kB of archives.\n","After this operation, 25.1 MB of additional disk space will be used.\n","Get:1 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy/main amd64 python3-gdal amd64 3.6.4+dfsg-1~jammy0 [1,027 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-numpy amd64 1:1.21.5-1ubuntu22.04.1 [3,467 kB]\n","Get:3 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy/main amd64 gdal-bin amd64 3.6.4+dfsg-1~jammy0 [561 kB]\n","Fetched 5,055 kB in 1s (6,051 kB/s)\n","Selecting previously unselected package python3-numpy.\n","(Reading database ... 121925 files and directories currently installed.)\n","Preparing to unpack .../python3-numpy_1%3a1.21.5-1ubuntu22.04.1_amd64.deb ...\n","Unpacking python3-numpy (1:1.21.5-1ubuntu22.04.1) ...\n","Selecting previously unselected package python3-gdal.\n","Preparing to unpack .../python3-gdal_3.6.4+dfsg-1~jammy0_amd64.deb ...\n","Unpacking python3-gdal (3.6.4+dfsg-1~jammy0) ...\n","Selecting previously unselected package gdal-bin.\n","Preparing to unpack .../gdal-bin_3.6.4+dfsg-1~jammy0_amd64.deb ...\n","Unpacking gdal-bin (3.6.4+dfsg-1~jammy0) ...\n","Setting up python3-numpy (1:1.21.5-1ubuntu22.04.1) ...\n","Setting up python3-gdal (3.6.4+dfsg-1~jammy0) ...\n","Setting up gdal-bin (3.6.4+dfsg-1~jammy0) ...\n","Processing triggers for man-db (2.10.2-1) ...\n"]}],"source":["!apt install gdal-bin -q"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xhoPC2omVUMI"},"outputs":[],"source":["import os\n","import glob\n","import requests\n","import zipfile\n","from osgeo import gdal, osr, ogr\n","import rasterio\n","import pandas as pd\n","import geopandas as gpd\n","import numpy as np\n","import subprocess\n","from rasterio.warp import reproject, Resampling\n","from rasterio.windows import Window\n","from concurrent.futures import ThreadPoolExecutor\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lh2Yz1UaVWZC"},"outputs":[],"source":["\n","\n","# # Directory to extract files\n","# extract_dir = \"/content/drive/MyDrive/GHS_POP_DATA\"\n","\n","# # Create directory if it doesn't exist\n","# os.makedirs(extract_dir, exist_ok=True)\n","\n","# # Function to download, unzip, and delete zip file\n","# def download_and_extract(url, extract_to):\n","#     local_filename = url.split(\"/\")[-1]\n","#     # Download the file\n","#     response = requests.get(url)\n","#     with open(local_filename, 'wb') as file:\n","#         file.write(response.content)\n","#     # Unzip the file\n","#     with zipfile.ZipFile(local_filename, 'r') as zip_ref:\n","#         zip_ref.extractall(extract_to)\n","#     # Delete the zip file\n","#     os.remove(local_filename)\n","\n","# # Process each URL\n","# for year in range(1975,2030,5):\n","#     url = f\"https://jeodpp.jrc.ec.europa.eu/ftp/jrc-opendata/GHSL/GHS_POP_GLOBE_R2023A/GHS_POP_E{year}_GLOBE_R2023A_4326_30ss/V1-0/GHS_POP_E{year}_GLOBE_R2023A_4326_30ss_V1_0.zip\"\n","#     download_and_extract(url, extract_dir)\n","\n","# # List the extracted files\n","# extracted_files = os.listdir(extract_dir)\n","# print(extracted_files)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hgx3IMhxsORS"},"outputs":[],"source":["#build vrt\n","folder_pop = \"/content/drive/MyDrive/GHS_POP_DATA\"\n","# List all files and directories in the specified folder\n","tif_files = glob.glob(os.path.join(folder_pop, '*.tif'))\n","os.chdir(folder_pop)\n","vrt_path ='GHS_POP.vrt'  # path to vrt to build\n","ds = gdal.BuildVRT(vrt_path, tif_files, options=gdal.BuildVRTOptions(separate=True,srcNodata=-200, VRTNodata=np.nan))\n","ds.FlushCache()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ja5lWjx4JNZ4"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OygMd3Oulfq-"},"outputs":[],"source":["######for stats start here"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"scS5x_ma-lJB","outputId":"b9535b74-b0ab-478e-fdcf-b7f2fa96dd89"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-6-51c76ee5e2b8>:1: DtypeWarning: Columns (3,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df_wpp_prediction = pd.read_csv(\"/content/drive/MyDrive/CCRI/WPP2022_prediction.csv\")\n","<ipython-input-6-51c76ee5e2b8>:2: DtypeWarning: Columns (3,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df_wpp_estimate = pd.read_csv(\"/content/drive/MyDrive/CCRI/WPP2022_estimate.csv\")\n"]}],"source":["df_wpp_prediction = pd.read_csv(\"/content/drive/MyDrive/CCRI/WPP2022_prediction.csv\")\n","df_wpp_estimate = pd.read_csv(\"/content/drive/MyDrive/CCRI/WPP2022_estimate.csv\")\n","df_wpp = pd.concat([df_wpp_estimate,df_wpp_prediction], ignore_index=True)\n","country_bnd = gpd.read_file('/content/drive/MyDrive/CCRI/global_bnd_adm0.geojson')\n","\n","# Merge polygons with the same ISO3 code\n","country_bnd = country_bnd.dissolve(by='iso3')\n","country_bnd = country_bnd.reset_index()"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"wl_4tTx3L_XB","executionInfo":{"status":"ok","timestamp":1719775191920,"user_tz":240,"elapsed":584,"user":{"displayName":"Do-Hyung Kim","userId":"04028744741058070758"}}},"outputs":[],"source":["# Path to the VRT file\n","pop_vrt_path = \"/content/drive/MyDrive/GHS_POP_DATA/GHS_POP.vrt\"\n","file_1960s = \"/content/drive/MyDrive/hwi_stats/dgca/average_hwi_1960s.tif\"\n","file_2020s = \"/content/drive/MyDrive/hwi_stats/dgca/average_hwi_2020s.tif\"\n","\n","# Create the output directory if it doesn't exist\n","output_dir = \"/content/drive/MyDrive/POP_stat\"\n","os.makedirs(output_dir, exist_ok=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mEvC_7Aysxlb"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":110,"metadata":{"id":"6aKW1Ek1sxhl","executionInfo":{"status":"ok","timestamp":1719784798225,"user_tz":240,"elapsed":260,"user":{"displayName":"Do-Hyung Kim","userId":"04028744741058070758"}}},"outputs":[],"source":["import os\n","import rasterio\n","import numpy as np\n","import pandas as pd\n","from shapely.geometry import mapping\n","from rasterio.mask import mask\n","from concurrent.futures import ProcessPoolExecutor\n","from shapely.geometry import MultiPolygon\n","import tempfile\n","import fiona\n","\n","\n","def calculate_exposure(iso3, pop_vrt_path, file_1960s, file_2020s, df_wpp, year, output_dir):\n","    \"\"\"Calculates exposure metrics for a given ISO3 code and writes results to a CSV file.\"\"\"\n","    print(f\"Processing {iso3}\")\n","    child_percent = df_wpp.loc[(df_wpp['ISO3 Alpha-code'] == iso3) & (df_wpp['Year'] == year), '0-17']\n","    if child_percent.empty:\n","      print(f\"No population data for {iso3} in {year}\")\n","      return None\n","\n","\n","\n","    filtered_gdf = country_bnd[country_bnd['iso3'] == iso3]\n","    # Create a temporary filtered GeoJSON file\n","    filtered_geojson_path = f'/content/drive/MyDrive/POP_stat/filtered_{iso3}.geojson'\n","    filtered_gdf.to_file(filtered_geojson_path, driver='GeoJSON')\n","\n","\n","    subset_pop_path = os.path.join(output_dir, f\"{iso3}_pop_subset.tif\")\n","    subset_T1_path = os.path.join(output_dir, f\"{iso3}_T1_subset.tif\")\n","    subset_T2_path = os.path.join(output_dir, f\"{iso3}_T2_subset.tif\")\n","\n","    def clip_raster(input_path, output_path, filtered_geojson_path, iso3_value):\n","\n","      # Clip the raster using gdalwarp with the filtered GeoJSON file\n","      warp_options = gdal.WarpOptions(\n","          cutlineDSName=filtered_geojson_path,\n","          cropToCutline=True,\n","          dstAlpha=True,\n","          format='GTiff',\n","          creationOptions=[\"COMPRESS=LZW\"]\n","      )\n","\n","      gdal.Warp(destNameOrDestDS=output_path, srcDSOrSrcDSTab=input_path, options=warp_options)\n","\n","    # Clip each input raster to the subset paths\n","    try:\n","        clip_raster(pop_vrt_path, subset_pop_path, filtered_geojson_path, iso3)\n","        clip_raster(file_1960s, subset_T1_path, filtered_geojson_path, iso3)\n","        clip_raster(file_2020s, subset_T2_path, filtered_geojson_path, iso3)\n","    except Exception as e:\n","        print(f\"Error during raster clipping: {e}\")\n","        return None\n","\n","    data_T1, data_T2 = {}, {}\n","    pop_band = (year - 1975) // 5 + 1\n","    try:\n","        with rasterio.open(subset_pop_path) as pop_src:\n","            total_pop = np.nansum(pop_src.read(pop_band))\n","            child_percent = df_wpp.loc[(df_wpp['ISO3 Alpha-code'] == iso3) & (df_wpp['Year'] == year), '0-17']\n","            if child_percent.empty:\n","                print(f\"No population data for {iso3} in {year}\")\n","                for path in [subset_pop_path, subset_T1_path, subset_T2_path]:\n","                    os.remove(path)\n","                return None\n","            child_percent = float(child_percent.values[0])\n","            child_pop = pop_src.read(pop_band) * (child_percent / 100)\n","    except Exception as e:\n","        print(f\"Error reading {subset_pop_path}: {e}\")\n","        for path in [subset_pop_path, subset_T1_path, subset_T2_path]:\n","                    os.remove(path)\n","        return None\n","\n","    def read_data(file_path, data_dict):\n","        try:\n","            with rasterio.open(file_path) as src:\n","                data_dict['hw_count'] = src.read(1)\n","                with np.errstate(divide='ignore', invalid='ignore'):\n","                    hw_count = src.read(1)\n","                    hw_days = src.read(2)\n","                    hw_days_per_count = np.where(hw_count == 0, 0, hw_days / hw_count)\n","                    data_dict['hw_days'] = hw_days_per_count\n","                data_dict['hw_temp_diff'] = src.read(3)\n","                data_dict['high_temp_degree_days'] = src.read(4)\n","        except Exception as e:\n","            print(f\"Error reading {file_path}: {e}\")\n","\n","    read_data(subset_T1_path, data_T1)\n","    read_data(subset_T2_path, data_T2)\n","\n","    results = {'iso3': iso3}\n","    results[\"total_pop\"] = total_pop\n","    results[\"child_pop\"] = np.nansum(child_pop)\n","    results[\"child_percent\"] = child_percent\n","\n","    for key in data_T1.keys():\n","        percentage_increase = np.zeros_like(data_T1[key], dtype=float)\n","        with np.errstate(divide='ignore', invalid='ignore'):\n","            data_T1_key = data_T1[key]\n","            data_T2_key = data_T2[key]\n","             # Case 1: Both T1 and T2 are zero\n","            both_zero_mask = (data_T1_key == 0) & (data_T2_key == 0)\n","\n","            percentage_increase[both_zero_mask] = 0\n","\n","            # Case 2: T1 is zero and T2 is not zero\n","            T1_zero_T2_nonzero_mask = (data_T1_key == 0) & (data_T2_key != 0)\n","            percentage_increase[T1_zero_T2_nonzero_mask] = np.inf\n","\n","            # Case 3: T1 is not zero\n","            T1_nonzero_mask = data_T1_key != 0\n","            percentage_increase[T1_nonzero_mask] = ((data_T2_key[T1_nonzero_mask] - data_T1_key[T1_nonzero_mask]) / data_T1_key[T1_nonzero_mask]) * 100\n","\n","            for threshold in [50, 100, 200]:\n","                mask_thresh = percentage_increase > threshold\n","                results[f\"exposure_{key}_{threshold}\"] = np.nansum(child_pop[mask_thresh])\n","\n","    # Clean up temporary subset files (optional)\n","    for path in [subset_pop_path, subset_T1_path, subset_T2_path, filtered_geojson_path]:\n","         os.remove(path)\n","\n","    return results\n"]},{"cell_type":"code","execution_count":113,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2799605,"status":"ok","timestamp":1719787697579,"user":{"displayName":"Do-Hyung Kim","userId":"04028744741058070758"},"user_tz":240},"id":"zouVzxO5emih","outputId":"5adda604-02c2-4c3d-cd8e-da44a09bfecb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Processing ABW\n","Processing AFG\n","Processing AGO\n","Processing AIA\n","Processing ALA\n","No population data for ALA in 2025\n","Processing ALB\n","Processing AND\n","Processing ARE\n","Processing ARG\n","Processing ARM\n","Processing ASM\n","Processing ATA\n","No population data for ATA in 2025\n","Processing ATF\n","No population data for ATF in 2025\n","Processing ATG\n","Processing AUS\n","Processing AUT\n","Processing AZE\n","Processing BDI\n","Processing BEL\n","Processing BEN\n","Processing BES\n","Processing BFA\n","Processing BGD\n","Processing BGR\n","Processing BHR\n","Processing BHS\n","Processing BIH\n","Processing BLM\n","Processing BLR\n","Processing BLZ\n","Processing BMU\n","Processing BOL\n","Processing BRA\n","Processing BRB\n","Processing BRN\n","Processing BTN\n","Processing BVT\n","No population data for BVT in 2025\n","Processing BWA\n","Processing CAF\n","Processing CAN\n","Processing CCK\n","No population data for CCK in 2025\n","Processing CHE\n","Processing CHL\n","Processing CHN\n","Processing CIV\n","Processing CMR\n","Processing COD\n","Processing COG\n","Processing COK\n","Processing COL\n","Processing COM\n","Processing CPV\n","Processing CRI\n","Processing CUB\n","Processing CUW\n","Processing CXR\n","No population data for CXR in 2025\n","Processing CYM\n","Processing CYP\n","Processing CZE\n","Processing DEU\n","Processing DJI\n","Processing DMA\n","Processing DNK\n","Processing DOM\n","Processing DZA\n","Processing ECU\n","Processing EGY\n","Processing ERI\n","Processing ESH\n","Processing ESP\n","Processing EST\n","Processing ETH\n","Processing FIN\n","Processing FJI\n","Processing FLK\n","Processing FRA\n","Processing FRO\n","Processing FSM\n","Processing GAB\n","Processing GBR\n","Processing GEO\n","Processing GGY\n","Processing GHA\n","Processing GIB\n","Processing GIN\n","Processing GLP\n","Processing GMB\n","Processing GNB\n","Processing GNQ\n","Processing GRC\n","Processing GRD\n","Processing GRL\n","Processing GTM\n","Processing GUF\n","Processing GUM\n","Processing GUY\n","Processing HKG\n","Processing HMD\n","No population data for HMD in 2025\n","Processing HND\n","Processing HRV\n","Processing HTI\n","Processing HUN\n","Processing IDN\n","Processing IMN\n","Processing IND\n","Processing IOT\n","No population data for IOT in 2025\n","Processing IRL\n","Processing IRN\n","Processing IRQ\n","Processing ISL\n","Processing ISR\n","Processing ITA\n","Processing JAM\n","Processing JEY\n","Processing JOR\n","Processing JPN\n","Processing KAZ\n","Processing KEN\n","Processing KGZ\n","Processing KHM\n","Processing KIR\n","Processing KNA\n","Processing KOR\n","Processing KWT\n","Processing LAO\n","Processing LBN\n","Processing LBR\n","Processing LBY\n","Processing LCA\n","Processing LIE\n","Processing LKA\n","Processing LSO\n","Processing LTU\n","Processing LUX\n","Processing LVA\n","Processing MAC\n","Processing MAF\n","Processing MAR\n","Processing MCO\n","Processing MDA\n","Processing MDG\n","Processing MDV\n","Processing MEX\n","Processing MHL\n","Processing MKD\n","Processing MLI\n","Processing MLT\n","Processing MMR\n","Processing MNE\n","Processing MNG\n","Processing MNP\n","Processing MOZ\n","Processing MRT\n","Processing MSR\n","Processing MTQ\n","Processing MUS\n","Processing MWI\n","Processing MYS\n","Processing MYT\n","Processing NAM\n","Processing NCL\n","Processing NER\n","Processing NFK\n","No population data for NFK in 2025\n","Processing NGA\n","Processing NIC\n","Processing NIU\n","Processing NLD\n","Processing NOR\n","Processing NPL\n","Processing NRU\n","Processing NZL\n","Processing OMN\n","Processing PAK\n","Processing PAN\n","Processing PCN\n","No population data for PCN in 2025\n","Processing PER\n","Processing PHL\n","Processing PLW\n","Processing PNG\n","Processing POL\n","Processing PRI\n","Processing PRK\n","Processing PRT\n","Processing PRY\n","Processing PSE\n","Processing PYF\n","Processing QAT\n","Processing REU\n","Processing ROU\n","Processing RUS\n","Processing RWA\n","Processing SAU\n","Processing SDN\n","Processing SEN\n","Processing SGP\n","Processing SGS\n","No population data for SGS in 2025\n","Processing SHN\n","Processing SJM\n","No population data for SJM in 2025\n","Processing SLB\n","Processing SLE\n","Processing SLV\n","Processing SMR\n","Processing SOM\n","Processing SPM\n","Processing SRB\n","Processing SSD\n","Processing STP\n","Processing SUR\n","Processing SVK\n","Processing SVN\n","Processing SWE\n","Processing SWZ\n","Processing SXM\n","Processing SYC\n","Processing SYR\n","Processing TCA\n","Processing TCD\n","Processing TGO\n","Processing THA\n","Processing TJK\n","Processing TKL\n","Processing TKM\n","Processing TLS\n","Processing TON\n","Processing TTO\n","Processing TUN\n","Processing TUR\n","Processing TUV\n","Processing TWN\n","Processing TZA\n","Processing UGA\n","Processing UKR\n","Processing UMI\n","No population data for UMI in 2025\n","Processing URY\n","Processing USA\n","Processing UZB\n","Processing VAT\n","No population data for VAT in 2025\n","Processing VCT\n","Processing VEN\n","Processing VGB\n","Processing VIR\n","Processing VNM\n","Processing VUT\n","Processing WLF\n","Processing WSM\n","Processing YEM\n","Processing ZAF\n","Processing ZMB\n","Processing ZWE\n","Processing xAB\n","No population data for xAB in 2025\n","Processing xAC\n","No population data for xAC in 2025\n","Processing xAP\n","No population data for xAP in 2025\n","Processing xFR\n","No population data for xFR in 2025\n","Processing xJK\n","No population data for xJK in 2025\n","Processing xJL\n","No population data for xJL in 2025\n","Processing xPI\n","No population data for xPI in 2025\n","Processing xRI\n","No population data for xRI in 2025\n","Processing xSI\n","No population data for xSI in 2025\n","Processing xSK\n","No population data for xSK in 2025\n","Processing xSR\n","No population data for xSR in 2025\n","Processing xUK\n","No population data for xUK in 2025\n","Processing xxx\n","No population data for xxx in 2025\n"]}],"source":["# Parallel processing setup\n","results_list = []\n","iso3_codes = country_bnd['iso3'].unique()\n","year = 2025\n","max_workers = 2\n","with ThreadPoolExecutor(max_workers=max_workers) as executor:\n","    futures = {executor.submit(calculate_exposure, iso3, pop_vrt_path, file_1960s, file_2020s, df_wpp, year, output_dir): iso3 for iso3 in iso3_codes}\n","\n","    for future in futures:\n","        result = future.result()\n","        if result is not None:\n","            results_list.append(result)\n","\n","# Combine results and write to a single CSV\n","all_results_df = pd.DataFrame(results_list)\n","all_results_df.to_csv(os.path.join(output_dir, \"all_exposure_results_high_res.csv\"), index=False)"]},{"cell_type":"code","source":[],"metadata":{"id":"QL9llYQDFcmB"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[{"file_id":"1wp05wbXYsvlQ3w2zFZAcIRp5XAZKAUk7","timestamp":1719773747099}],"authorship_tag":"ABX9TyNdSUY7Fwh8z6LC+45aemVf"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}