{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxXtOp6VLhmf",
        "outputId": "d5042831-35d4-4ad4-cfe1-a5cd51420990"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cartopy rasterio rasterstats -q"
      ],
      "metadata": {
        "id": "YA7zsVoVqu9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "54OHtsiwDXas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ee\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import numpy as np\n",
        "import time\n",
        "from rasterstats import zonal_stats\n",
        "import rasterio\n",
        "import os\n",
        "import cartopy.crs as ccrs\n",
        "\n",
        "import glob\n",
        "import requests\n",
        "import zipfile\n",
        "from osgeo import gdal, osr, ogr\n",
        "import numpy as np\n",
        "import subprocess\n",
        "from rasterio.warp import reproject, Resampling\n",
        "from rasterio.windows import Window\n",
        "from concurrent.futures import ThreadPoolExecutor\n"
      ],
      "metadata": {
        "id": "BYCac8ENDFD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_folder = '/content/drive/MyDrive/hwi_product'\n",
        "output_folder = '/content/drive/MyDrive/hwi_stats/dgca_back'"
      ],
      "metadata": {
        "id": "cdqpyH2kFxx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0nWg_sGU_u6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the input files for each decade\n",
        "decades = ['1960s', '1970s', '1980s', '1990s', '2000s', '2010s', '2020s']\n",
        "data_files = {decade: os.path.join(output_folder, f'average_hwi_{decade}.tif') for decade in decades}\n",
        "\n",
        "# Initialize dictionary to hold data for each decade\n",
        "data_decades = {decade: {} for decade in decades}\n",
        "\n",
        "with rasterio.open('/content/drive/MyDrive/hwi_product/hwi_1960s/temp.vrt') as src:\n",
        "    # Read the land mask\n",
        "    land_mask = src.read(1)\n",
        "    land_mask_nan = np.where(land_mask != 1, np.nan, 1)\n",
        "\n",
        "# Function to read data from a file and store in the dictionary\n",
        "def read_data(file_path, data_dict):\n",
        "    if os.path.exists(file_path):\n",
        "        with rasterio.open(file_path) as src:\n",
        "            data_dict['hw_count'] = src.read(1) * land_mask_nan\n",
        "            data_dict['hw_days'] = src.read(2)/src.read(1) * land_mask_nan\n",
        "            data_dict['hw_temp_diff'] = src.read(3) * land_mask_nan\n",
        "            data_dict['high_temp_degree_days'] = src.read(4) * land_mask_nan\n",
        "\n",
        "# Read data for each decade\n",
        "for decade in decades:\n",
        "    read_data(data_files[decade], data_decades[decade])\n",
        "\n",
        "# Combine data for all decades to calculate overall mean and standard deviation\n",
        "combined_data = {indicator: [] for indicator in data_decades['1960s'].keys()}\n",
        "for decade in decades:\n",
        "    for indicator in combined_data.keys():\n",
        "        combined_data[indicator].append(data_decades[decade][indicator])\n",
        "\n",
        "# Calculate global mean and standard deviation across all decades and spatial dimensions\n",
        "mean_values = {indicator: np.nanmean(np.stack(combined_data[indicator]), axis=(0, 1, 2)) for indicator in combined_data.keys()}\n",
        "std_dev = {indicator: np.nanstd(np.stack(combined_data[indicator]), axis=(0, 1, 2)) for indicator in combined_data.keys()}\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "w2N_z998Fl5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_wpp_prediction = pd.read_csv(\"/content/drive/MyDrive/CCRI/WPP2022_prediction.csv\")\n",
        "df_wpp_estimate = pd.read_csv(\"/content/drive/MyDrive/CCRI/WPP2022_estimate.csv\")\n",
        "df_wpp = pd.concat([df_wpp_estimate,df_wpp_prediction], ignore_index=True)\n",
        "country_bnd = gpd.read_file('/content/drive/MyDrive/CCRI/global_bnd_adm0.geojson')\n",
        "\n",
        "# Merge polygons with the same ISO3 code\n",
        "country_bnd = country_bnd.dissolve(by='iso3')\n",
        "country_bnd = country_bnd.reset_index()\n"
      ],
      "metadata": {
        "id": "0DNjf-TzC5hN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import rasterio\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from shapely.geometry import mapping\n",
        "from rasterio.mask import mask\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "\n",
        "def calculate_exposure(iso3, pop_vrt_path, file_T, df_wpp, year, output_dir, mean_values, std_dev):\n",
        "    \"\"\"Calculates exposure metrics for a given ISO3 code and writes results to a CSV file.\"\"\"\n",
        "    print(f\"Processing {iso3} , {year}\")\n",
        "\n",
        "    child_percent = df_wpp.loc[(df_wpp['ISO3 Alpha-code'] == iso3) & (df_wpp['Year'] == year), '0-17']\n",
        "    if child_percent.empty:\n",
        "      print(f\"No population data for {iso3} in {year}\")\n",
        "      return None\n",
        "\n",
        "    filtered_gdf = country_bnd[country_bnd['iso3'] == iso3]\n",
        "    # Create a temporary filtered GeoJSON file\n",
        "    filtered_geojson_path = f'/content/drive/MyDrive/POP_stat_extreme/filtered_{iso3}.geojson'\n",
        "    filtered_gdf.to_file(filtered_geojson_path, driver='GeoJSON')\n",
        "\n",
        "    subset_pop_path = os.path.join(output_dir, f\"{iso3}_pop_subset.tif\")\n",
        "    subset_T_path = os.path.join(output_dir, f\"{iso3}_T_subset.tif\")\n",
        "\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    def clip_raster(input_path, output_path, filtered_geojson_path, iso3_value):\n",
        "\n",
        "      # Clip the raster using gdalwarp with the filtered GeoJSON file\n",
        "      warp_options = gdal.WarpOptions(\n",
        "          cutlineDSName=filtered_geojson_path,\n",
        "          cropToCutline=True,\n",
        "          dstAlpha=True,\n",
        "          format='GTiff',\n",
        "          creationOptions=[\"COMPRESS=LZW\"]\n",
        "      )\n",
        "\n",
        "      gdal.Warp(destNameOrDestDS=output_path, srcDSOrSrcDSTab=input_path, options=warp_options)\n",
        "\n",
        "    # Clip each input raster to the subset paths\n",
        "    try:\n",
        "        clip_raster(pop_vrt_path, subset_pop_path, filtered_geojson_path, iso3)\n",
        "        clip_raster(file_T, subset_T_path, filtered_geojson_path, iso3)\n",
        "    except Exception as e:\n",
        "        print(f\"Error during raster clipping: {e}\")\n",
        "        return None\n",
        "\n",
        "    data_T = {}\n",
        "    pop_band = (year - 1975) // 5 + 1\n",
        "    try:\n",
        "        with rasterio.open(subset_pop_path) as pop_src:\n",
        "            total_pop = np.nansum(pop_src.read(pop_band))\n",
        "            child_percent = df_wpp.loc[(df_wpp['ISO3 Alpha-code'] == iso3) & (df_wpp['Year'] == year), '0-17']\n",
        "            if child_percent.empty:\n",
        "                print(f\"No population data for {iso3} in {year}\")\n",
        "                for path in [subset_pop_path, subset_T_path]:\n",
        "                    os.remove(path)\n",
        "                return None\n",
        "            child_percent = float(child_percent.values[0])\n",
        "            child_pop = pop_src.read(pop_band) * (child_percent / 100)\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading {subset_pop_path}: {e}\")\n",
        "        for path in [subset_pop_path, subset_T_path]:\n",
        "            os.remove(path)\n",
        "        return None\n",
        "\n",
        "    def read_data(file_path, data_dict):\n",
        "        try:\n",
        "            with rasterio.open(file_path) as src:\n",
        "                data_dict['hw_count'] = src.read(1)\n",
        "                with np.errstate(divide='ignore', invalid='ignore'):\n",
        "                    hw_count = src.read(1)\n",
        "                    hw_days = src.read(2)\n",
        "                    hw_days_per_count = np.where(hw_count == 0, 0, hw_days / hw_count)\n",
        "                    data_dict['hw_days'] = hw_days_per_count\n",
        "                data_dict['hw_temp_diff'] = src.read(3)\n",
        "                data_dict['high_temp_degree_days'] = src.read(4)\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading {file_path}: {e}\")\n",
        "\n",
        "    read_data(subset_T_path, data_T)\n",
        "\n",
        "    results = {'iso3': iso3}\n",
        "    results[\"total_pop\"] = total_pop\n",
        "    results[\"child_pop\"] = np.nansum(child_pop)\n",
        "    results[\"child_percent\"] = child_percent\n",
        "\n",
        "    for key in data_T.keys():\n",
        "        for std in [1, 2, 3]:\n",
        "            threshold_value = mean_values[key] + std * std_dev[key]\n",
        "            mask_high_percentage = data_T[key] > threshold_value\n",
        "            results[f\"exposure_{key}_{std}std_{year-5}s\"] = np.nansum(child_pop[mask_high_percentage])\n",
        "\n",
        "    # Clean up temporary subset files (optional)\n",
        "    for path in [subset_pop_path, subset_T_path, filtered_geojson_path]:\n",
        "        os.remove(path)\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "d4pIMPI0yO3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Path to the VRT file\n",
        "pop_vrt_path = \"/content/drive/MyDrive/GHS_POP_DATA/GHS_POP.vrt\"\n",
        "\n",
        "# Create the output directory if it doesn't exist\n",
        "output_dir = \"/content/drive/MyDrive/POP_stat_extreme\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "for year in range(1970, 2030, 10):\n",
        "  file_T = f\"/content/drive/MyDrive/hwi_stats/dgca/average_hwi_{year}s.tif\"\n",
        "  pop_year = year +5\n",
        "\n",
        "  results_list = []\n",
        "  iso3_codes = country_bnd['iso3'].unique()\n",
        "\n",
        "  with ThreadPoolExecutor(max_workers=3) as executor:\n",
        "      futures = {executor.submit(calculate_exposure, iso3, pop_vrt_path, file_T, df_wpp, pop_year, output_dir, mean_values, std_dev): iso3 for iso3 in iso3_codes}\n",
        "      for future in futures:\n",
        "          result = future.result()\n",
        "          if result is not None:\n",
        "              results_list.append(result)\n",
        "\n",
        "  # Combine results and write to a single CSV\n",
        "  all_results_df = pd.DataFrame(results_list)\n",
        "  all_results_df.to_csv(os.path.join(output_dir, f\"extreme_exposure_results_{year}s_high_res.csv\"), index=False)"
      ],
      "metadata": {
        "id": "oOISGlwzBKnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yf0lL9uBNXuL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}